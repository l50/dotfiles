# Terminates a process given its name (case-insensitive)
#
# Usage:
#   process_terminator [process_name]
#
# Output:
#   No output, but terminates the specified process.
#
# Example(s):
#   process_terminator "myprocess"
process_terminator () {
  if pgrep -i "$1" > /dev/null
  then
    pkill -i "$1"
    echo "Process $1 has been terminated."
  else
    echo "No processes found with the name: $1"
  fi
}

# An abstraction to get content from various compressed files.
#
# Usage:
#   extract [file] [directory]
#
# Output:
#   Extracts the content of the specified compressed file.
#
# Example(s):
#   extract archive.tar.gz
extract() {
	if [ -f "$1" ]; then
		dir=${2:-.}  # If no directory specified, use current directory
		case "$1" in
		*.tar.bz2) tar xvjf "$1" -C "$dir" ;;
		*.tar.gz) tar xvzf "$1" -C "$dir" ;;
		*.bz2) bunzip2 "$1" ;;
		*.rar) rar x "$1" "$dir" ;;
		*.gz) gunzip "$1" ;;
		*.tar) tar xvf "$1" -C "$dir" ;;
		*.tbz2) tar xvjf "$1" -C "$dir" ;;
		*.tgz) tar xvzf "$1" -C "$dir" ;;
		*.zip) unzip "$1" -d "$dir" ;;
		*.Z) uncompress "$1" ;;
		*.7z) 7z x "$1" -o"$dir" ;;
		*) echo "don't know how to extract '$1'..." ;;
		esac
	else
		echo "'$1' is not a valid file!"
	fi
}

# Determines the size of a file or total size of a directory.
#
# Usage:
#   fs [file|directory]
#
# Output:
#   Prints the size of the specified file or total size of the specified directory.
#
# Example(s):
#   fs myfile.txt
#   fs mydirectory
fs() {
  if du -b /dev/null >/dev/null 2>&1; then
    local arg=-sbh
  else
    local arg=-sh
  fi
  if [[ -n $* ]]; then
    for file in "$@"; do
      du "$arg" -- "./$file"
    done
  else
    du "$arg" ./*[^.]* -- *
  fi
}

# Changes the current directory to the root of the current Git repository.
#
# Usage:
#   repo_root
#
# Output:
#   Changes the current directory to the root of the current Git repository. If
#   the current directory is not part of a Git repository, prints an error message.
#
# Example(s):
#   repo_root
repo_root() {
  local root
  root=$(git rev-parse --show-toplevel 2> /dev/null)
  if [[ ! -z "${root}" ]]; then
    cd "${root}" || exit 1
  else
    echo "Current directory is not part of a git repository."
  fi
}

# Extracts only the comments from the contents of the specified file or from stdin.
# It supports extracting single-line comments that start with // or #, as
# well as multi-line comments that start with /* and end with */.
# The extracted comments are then printed to stdout, with each comment on a separate line.
#
# Usage:
#   onlycomments [file_path]
#   echo 'code with // comments' | onlycomments
#
# Output
#   Only the comments extracted from the file or stdin, with each comment on a separate line.
#
# Example(s):
#   onlycomments "file.go"
#   echo 'code with // comments' | onlycomments
onlycomments () {
    if [ $# -eq 0 ]
    then
        grep -E '(//.*|/\*.*\*/|#.*)$'
    else
        file_path="$1"
        grep -E '(//.*|/\*.*\*/|#.*)$' "$file_path"
    fi
}

# Removes all comments from the contents of the specified file or from stdin.
# Supports removing single-line comments that start with // or #, as well
# as multi-line comments that start with /* and end with */. The modified
# contents are then printed to stdout.
#
# Usage:
#   nocomment [file_path]
#   echo 'code with // comments' | nocomment
#
# Output:
#   The contents of the file or stdin without comments.
#
# Example(s):
#   nocomment "file.go"
#   echo 'code with // comments' | nocomment
nocomment() {
    if [ $# -eq 0 ]
    then
        sed -e 's://.*$::g' -e 's/#.*$//g' -e '/\/\*/,/\*\//d' -e '/^\s*$/d'
    else
        file_path="$1"
        sed -e 's://.*$::g' -e 's/#.*$//g' -e '/\/\*/,/\*\//d' -e '/^\s*$/d' "$file_path"
    fi
}

# Installs oh-my-zsh if it's not already installed.
#
# Usage:
#   install_oh_my_zsh
install_oh_my_zsh() {
    # Check if oh-my-zsh is installed
    if [ ! -d "${HOME}/.oh-my-zsh" ]; then
        echo -e "${BLUE}Installing oh-my-zsh, please wait...${RESET}"
        sh -c "$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)"
    else
        echo -e "${YELLOW}oh-my-zsh is already installed.${RESET}"
    fi
}

# Returns a list of tmux sessions and the processes running in each pane.
#
# Usage:
#   tmux_sessions
#
# Output:
#   Prints the name of each tmux session and the processes running in each pane.
#
tmux_sessions() {
	for s in $(tmux list-sessions -F '#{session_name}'); do
		echo -e "\ntmux session name: $s\n--------------------"
		for p in $(tmux list-panes -s -F '#{pane_pid}' -t "$s"); do
			pstree -p -a "$p"
		done
	done
}

# Run tmux source-file ~/.tmux.conf on all panes
source_tmux_conf() {
	session=$(tmux display-message -p "#S")

	for pane in $(tmux list-panes -s -F "#{pane_id}"); do
		tmux send-keys -t "$session.$pane" "tmux source-file ~/.tmux.conf" C-m
	done
}

# Monitor ICMP traffic - great for OOB testing.
icmpMonitor() {
	tcpdump -i "$1" 'icmp and icmp[icmptype]=icmp-echo'
}

# get a line from a particular file
# input line number and file
# example: get_line 200 output.txt
get_line() {
	sed "$1q;d" "$2"
}

# Check spelling of markdown files in the current directory
spell-check-md() {
	for file in *.md; do
		aspell check --mode=markdown --lang=en "${file}"
	done
}

alias randommacaddrwifi="sudo spoof-mac randomize wi-fi"
alias diff="colordiff"

# Used to clone a web site - takes a website as the parameter
alias cloneSite="wget --mirror --convert-links --adjust-extension --page-requisites --no-parent"

# Get Public IP and Geolocation data
alias publicIP="curl -s https://ipapi.co/\$(curl -s ifconfig.me)/json | jq"

# If we are not on an OSX system
if [[ $(uname) != 'Darwin' ]]; then
	alias open="xdg-open"
	alias openPorts="netstat -ntlp | grep LISTEN"
	# Largest files in the current directory and below
	alias largestFilesAndFolders="du -Sh | sort -rh | head -5"
	alias totalDisk='fdisk -l | grep Disk'
	# Find alias with zsh
	if test "$(which zsh)"; then
		alias zshAliasLocation="PS4='+%x:%I>' zsh -i -x -c '' |& grep"
	fi
	alias l.='ls -d .* --color=auto'
fi

# Repo Sync
# Synchronizes files between two git repositories while excluding .git directory.
#
# Usage:
#   repo_sync [source_directory] [target_directory]
#
# Output:
#   No output, but copies files from source directory to target directory.
#
# Example(s):
#   repo_sync "/path/to/src/repo" "/path/to/dest/repo"
repo_sync () {
  # Check if both directories exist
  if [[ -d "$1" ]] && [[ -d "$2" ]]; then
    # Use rsync to copy files from the source to the target
    rsync -av --exclude='.git/' "$1/" "$2/"
    echo "Sync complete."
  else
    echo "One or both directories do not exist. Please check the paths and try again."
  fi
}

# Get JSON Keys
# Fetches all the keys from a JSON file using jq.
#
# Usage:
#   getJSONKeys [json_file]
#
# Output:
#   Prints all the keys present in the JSON file.
#
# Example(s):
#   getJSONKeys "/path/to/jsonfile.json"
getJSONKeys() {
    jq 'keys' "$1"
}

# Get JSON Values
# Fetches all the values of array objects from a JSON file using jq.
#
# Usage:
#   getJSONValues [json_file]
#
# Output:
#   Prints all the values present in the JSON array objects.
#
# Example(s):
#   getJSONValues "/path/to/jsonfile.json"
getJSONValues() {
    jq '.[] | values' "$1"
}

# Downloads and installs a specific version of a tool from Github using the gh CLI tool or curl.
# The function fetches a binary tool from a GitHub releases page, filters releases based on the
# current system's architecture and OS, downloads the relevant release, extracts the downloaded
# archive, and moves the extracted binary to the specified destination directory (default: $HOME/.local/bin).
# Optionally, a GitHub token can be used if authenticated access is required.
#
# Usage:
#   fetchFromGithub [author] [repository_name] [version] [binary_name] [destination_directory]
#
# Output:
#   Downloads the relevant tool for the specified version, extracts the binary and moves it
#   to the specified destination directory or $HOME/.local/bin if not provided. Prints the success message and the name of the copied
#   file if the process was successful.
#
# Example(s):
#   fetchFromGithub "CowDogMoo" "Guacinator" "v1.0.0" "guacinator" # Downloads and installs v1.0.0 of the guacinator
#   fetchFromGithub "yourgithubname" "yourprivategithubrepo" "v0.0.1" "desiredbinname" "/custom/path" # Specifies a custom path for the binary
#
# Note:
#   The function requires jq and curl to be installed. The GITHUB_TOKEN environment variable can be set optionally for authenticated access.
#   If the function fails to find a relevant release for the system's OS and architecture, or if
#   the dependencies are not found, it will print an error message and return a non-zero status code.
fetchFromGithub() {
    AUTHOR="$1"
    REPO_NAME="$2"
    VERSION="$3"
    BIN_NAME="$4"
    DEST_DIR="${5:-$HOME/.local/bin}"

    # Ensure the destination directory exists
    mkdir -p "$DEST_DIR"

    os=$(uname | tr '[:upper:]' '[:lower:]')
    arch=$(uname -m)

    if [[ "$arch" == "x86_64" ]]; then arch="amd64"; fi
    if [[ "$arch" == "aarch64" ]]; then arch="arm64"; fi

    REPO="$AUTHOR/$REPO_NAME"

    # Check if curl is installed
    if ! command -v curl >/dev/null 2>&1; then
        echo "Error: curl is not installed. Please install curl and try again."
        return 1
    fi

    # Check if jq is installed
    if ! command -v jq >/dev/null 2>&1; then
        echo "Error: jq is not installed. Please install jq and try again."
        return 1
    fi

    if [[ -n "$GITHUB_TOKEN" ]] && command -v gh >/dev/null 2>&1; then
    echo "$GITHUB_TOKEN" | gh auth login --with-token
    assets_json=$(gh release view "$VERSION" --repo "$REPO" --json assets)

    if [ $? -ne 0 ]; then
        echo "No relevant release found for OS: $os, architecture: $arch"
        return 1
    fi

    assets=$(echo "$assets_json" | jq -r '.assets[].name')
    else
        assets=$(curl -s "https://api.github.com/repos/$REPO/releases/latest" \
        | jq -r '.assets[].browser_download_url')
    fi

    # Read assets into an array
    assets_array=()
    while IFS=$'\n' read -r line; do
        assets_array+=("$line")
    done <<< "$assets"

    # Flag to check if a matching asset was found
    asset_found=false
    # Iterate over the array and search for a match
    for asset in "${assets_array[@]}"; do
        if [[ $asset == *"$os"* && $asset == *"$arch"* ]]; then
            asset_found=true
            if [[ -n "$GITHUB_TOKEN" ]] && command -v gh >/dev/null 2>&1; then
                gh release download "$VERSION" --repo "$REPO" --pattern "$asset" -D "/tmp"
            else
                curl -sLo "/tmp/$(basename "$asset")" "$asset"
            fi
            echo "Download of $REPO_NAME release $VERSION from GitHub is complete."

            # Make sure the destination directory exists
            mkdir -p "$DEST_DIR"

            # Extract the tarball
            pushd "/tmp" || exit
            extract "$(basename "$asset")"

            # Only process the extracted files from the current asset
            for file in *; do
                if [[ "$file" == "$BIN_NAME" ]]; then
                    cp "$file" "$DEST_DIR/$BIN_NAME"
                    echo "Copied $file to $DEST_DIR/ as $BIN_NAME"
                    break # Exit the loop once the file is found and copied
                fi
            done
        fi
    done

    popd || exit
    if [ "$asset_found" = false ]; then
        echo "No relevant release found for OS: $os, architecture: $arch"
        return 1
    fi
}

function build_with_ansible_and_buildah() {
    # Ensure the playbook path and image name parameters are provided
    if [[ $# -lt 2 ]]; then
        echo "Error: Missing parameters."
        echo "Usage: $0 <playbook-path> <image-name>"
        return 1
    fi

    local playbook_path=$1
    local image_name=$2
    local playbook_dir
    playbook_dir=$(dirname "$playbook_path")
    local requirements_file="$playbook_dir/requirements.yml"

    # Check if Docker is installed
    if ! command -v docker &> /dev/null; then
        echo "Error: Docker is not installed. Please install Docker and try again."
        return 1
    fi

    # Check if the playbook file exists
    if [[ ! -f $playbook_path ]]; then
        echo "Error: Playbook file '$playbook_path' not found."
        return 1
    fi

    # Pull the Buildah Docker image if it's not already available
    if ! docker pull quay.io/buildah/stable; then
        echo "Error: Failed to pull Buildah Docker image from quay.io."
        return 1
    fi

    local -a volume_option=()
    if [[ -f $requirements_file ]]; then
        volume_option=(-v "$requirements_file:/project/requirements.yml")
    fi

     # Create ansible.cfg file
    cat > $(pwd)/ansible.cfg <<EOF
[defaults]
inventory = /project
roles_path = /project/roles
collections_paths = /project/collections
EOF

    # Run the custom Docker container to execute the Ansible playbook and build the specified image
    if ! docker run --rm -it --privileged \
        -v /var/run/docker.sock:/var/run/docker.sock \
        -v "$(pwd):/project" \
        -v "$playbook_path:/project/provision.yml" \
        "${volume_option[@]}" \
        custom-buildah-ansible bash -c \
        "buildah from --name working-container ubuntu \
          && buildah copy working-container /project /project \
          && buildah run working-container -- apt-get update \
          && buildah run --env DEBIAN_FRONTEND=noninteractive working-container -- apt-get install -y ansible git \
          && ( [[ -f /project/requirements.yml ]] && \
              buildah run working-container -- ansible-galaxy install -r /project/requirements.yml || true ) \
          && buildah run working-container -- ansible-playbook -c local -i 'localhost,' /project/provision.yml \
          && buildah commit working-container $image_name \
          && buildah push --format docker $image_name docker-archive:/project/$image_name.tar:$image_name \
          && buildah rm working-container"; then
        echo "Error: Failed to build the image $image_name."
        return 1
    fi

    # Copy the tar file from the Docker container to the host and load it into Docker
    if ! docker load -i $image_name.tar; then
        echo "Error: Failed to load the image $image_name."
        return 1
    fi

    echo "Image $image_name built successfully."
}

alias networkedComputers="arp -a |grep -oP '\d+\.\d+\.\d+\.\d+'"

# If gshuf and cowsay are installed, then evolve our vocab with cowsay
# https://www.quora.com/What-is-the-most-interesting-shell-script-you-have-ever-written
if hash cowsay 2>/dev/null && hash gshuf 2>/dev/null; then
	gshuf -n 1 "$HOME/.dotfiles/files/gre" | cowsay
fi

# Set alias for nmap if it's installed
# https://github.com/hriesco/dotfiles/blob/master/.aliases
if hash nmap 2>/dev/null; then
	alias nmap="nmap --reason --open --stats-every 3m --max-retries 1 --max-scan-delay 20 --defeat-rst-ratelimit"
fi

alias ipaddr="ifconfig | grep -Eo 'inet (addr:)?([0-9]*\.){3}[0-9]*' | grep -Eo '([0-9]*\.){3}[0-9]*' | grep -v '127.0.0.1'"
